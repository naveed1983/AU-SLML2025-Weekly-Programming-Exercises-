{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9 - Combining Models\n",
    "\n",
    "Learning contents:\n",
    "- Base Classifier\n",
    "    - Train a Least Squares classifier, perform a prediction on the samples, and compute the accuracy\n",
    "    - Plot the decision boundary for least squares classifier\n",
    "- Committees\n",
    "    - Split the training data into M=9 equally sized, non-overlapping parts\n",
    "    - Train M=9 Least Squares classifiers, one for each data split\n",
    "    - Perform predictions on the whole dataset using a comitteee of classifiers and compute the accuracy\n",
    "    - Plot the decision boundary for committee classifier\n",
    "- Decision tree\n",
    "    - Fit a DecisionTreeClassifier using scikit-learn, perform a prediction on the data, and compute the accuracy\n",
    "    - Plot the decision boundary for the DecisionTreeClassifier\n",
    "- AdaBoost\n",
    "    - Create an AdaBoost classifier of DecisionTreeClassifiers using the scikit-learn library\n",
    "    - Plot the decision boundary for the AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns; sns.set(); sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plotting functions, we'll be using later\n",
    "\n",
    "\n",
    "def plot_scatter(data, target, alpha=0.5, legend=True):\n",
    "    scatter = plt.scatter(data[:, 0], data[:, 1], c=target, edgecolor='none', alpha=alpha, cmap='rainbow')\n",
    "    if legend:\n",
    "        plt.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Targets\")\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    \n",
    "def plot_mesh(X, pred_fn, n_class=2):\n",
    "    plt_margin = 5\n",
    "    x_min, x_max = min(X[:,0]) - plt_margin, max(X[:,0]) + plt_margin\n",
    "    y_min, y_max = min(X[:,1]) - plt_margin, max(X[:,1]) + plt_margin\n",
    "    h = 0.1  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = pred_fn(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, alpha = 0.1, cmap=plt.cm.get_cmap('rainbow', n_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We'll be working with a slightly modified version of the digits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits(n_class=2)\n",
    "\n",
    "# Get a 2D version of the data using PCA\n",
    "pca = PCA(n_components=2)\n",
    "t = digits.target\n",
    "X = pca.fit_transform(digits.data)\n",
    "\n",
    "# In order to get a non-linearly seperable case, \n",
    "# we'll modify the data a bit this time, \n",
    "# translating the '-1' class to the right and up\n",
    "X = np.where(\n",
    "    np.repeat(np.expand_dims(t == 1, axis=1), 2, axis=1), \n",
    "    X, \n",
    "    np.vstack([X[:,0]+20, X[:,1]+10]).T\n",
    ")\n",
    "\n",
    "N = len(t) # total number of samples\n",
    "\n",
    "plot_scatter(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Base Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1) Train a Least Squares classifier, perform a prediction on the samples, and compute the accuracy\n",
    "Use your solution from the exercise \"Week 7 - Linear classification\" section 1.1 and 1.2. The accuracy is to be calculated in terms of the proportion of correct predictions compared to the number of predictions and should print a single float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2) Plot the decision boundary for least squares classifier\n",
    "Hint: you can do this by either plotting a line on the boundary or creating a mesh of all predictions (similar to section 1.3 in \"week 7 - Linear classification\"). You can of course use the helper functions (plot_scatter() and plot_mesh()) given at the start of this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Committees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Split the training data into M=9 equally sized, non-overlapping parts\n",
    "Hint: use the numpy.split() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Train M=9 Least Squares classifiers, one for each (9) data split using the same method as in section 0.1\n",
    "Hint: loop over the training data containing of the X split and t split zipped together using the zip() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Perform a prediction on the whole dataset using committee of classifiers (lecture 17 slide 4) and compute the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Plot the decision boundary for committee classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Fit a DecisionTreeClassifier imported from the `scikit-learn` library, perform a prediction on the data, and compute the accuracy\n",
    "Use `max_depth=3`. You will use fit() and predict() methods of the DecisionTreeClassifier class in order to respectively train and predict from your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Plot the decision boundary for the DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Create an AdaBoost classifier of DecisionTreeClassifiers using the `scikit-learn` library, and compute the accuracy\n",
    "Use a depth of 1 for the `DecisionTreeClassifier` and 7 estimators for the `AdaBoostClassifier`. Use the defaults for the other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Plot the decision boundary for the AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLcourse2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
